# Ravenhelm Platform - Integrations Stack
# ==========================================
# MCP tools, workflows, and voice/video
#
# Services: mcp-server-gitlab, n8n, livekit
# Dependencies: gitlab (for MCP), postgres (for n8n), redis (for livekit), localstack
#
# Start: docker compose -f compose/docker-compose.integrations.yml up -d

include:
  - docker-compose.base.yml

services:
  # =========================================================================
  # MCP SERVER - GitLab automation via Model Context Protocol
  # =========================================================================
  mcp-server-gitlab:
    build:
      context: ../services/mcp-server-gitlab
    container_name: gitlab-sre-mcp-gitlab
    user: "1001:1001"
    labels:
      - "ravenhelm.project=hlidskjalf-integrations"
      - "ravenhelm.service=mcp"
      - "ravenhelm.workload=gitlab"
    environment:
      - GITLAB_BASE_URL=https://gitlab.ravenhelm.test
      - GITLAB_API_URL=http://gitlab
      - GITLAB_PROJECT_PATH=ravenhelm/hlidskjalf
      - GITLAB_VERIFY_SSL=false
      - GITLAB_MCP_SECRET_NAME=ravenhelm/dev/gitlab/mcp_service
      - LOCALSTACK_ENDPOINT=http://localstack:4566
      - AWS_ACCESS_KEY_ID=test
      - AWS_SECRET_ACCESS_KEY=test
      - AWS_REGION=us-east-1
      - MCP_SERVICE_PORT=9400
      - TLS_REQUIRE_CLIENT_CERT=true
      - REQUESTS_CA_BUNDLE=/certs/mkcert-ca.crt
    extra_hosts:
      - "zitadel.ravenhelm.test:host-gateway"
    ports:
      - "9400:9400"
    volumes:
      - mcp_gitlab_certs:/run/spire/certs:ro
      - ../ravenhelm-proxy/config/certs/mkcert-ca.crt:/certs/mkcert-ca.crt:ro
    restart: unless-stopped
    networks:
      - platform_net

  # =========================================================================
  # N8N - Workflow Automation
  # =========================================================================
  n8n:
    image: n8nio/n8n:latest
    container_name: gitlab-sre-n8n
    labels:
      - "ravenhelm.project=hlidskjalf-integrations"
      - "ravenhelm.service=n8n"
      - "ravenhelm.workload=workflow"
    environment:
      - N8N_HOST=n8n.ravenhelm.test
      - N8N_PORT=5678
      - N8N_PROTOCOL=https
      - WEBHOOK_URL=https://n8n.ravenhelm.test/
      - DB_TYPE=postgresdb
      - DB_POSTGRESDB_HOST=postgres
      - DB_POSTGRESDB_PORT=5432
      - DB_POSTGRESDB_DATABASE=n8n
      - DB_POSTGRESDB_USER=postgres
      - DB_POSTGRESDB_PASSWORD=postgres
      - N8N_ENCRYPTION_KEY=ravenhelm-n8n-encryption-key
      - EXECUTIONS_DATA_PRUNE=true
      - EXECUTIONS_DATA_MAX_AGE=168
    volumes:
      - n8n_data:/home/node/.n8n
    ports:
      - "5678:5678"
    restart: unless-stopped
    networks:
      - platform_net

  # =========================================================================
  # LIVEKIT - WebRTC Server (Voice Agent Infrastructure)
  # =========================================================================
  livekit:
    image: livekit/livekit-server:latest
    container_name: gitlab-sre-livekit
    labels:
      - "ravenhelm.project=hlidskjalf-integrations"
      - "ravenhelm.service=livekit"
      - "ravenhelm.workload=voice"
    command:
      - --config=/etc/livekit.yaml
      - --dev
    ports:
      - "7880:7880"     # HTTP/WebSocket
      - "7881:7881"     # RTC/UDP
      - "7882:7882/udp" # RTC/UDP
    volumes:
      - ../livekit/livekit.yaml:/etc/livekit.yaml:ro
    environment:
      LIVEKIT_KEYS: "${LIVEKIT_KEYS:-devkey: secret}"
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:7880"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    restart: unless-stopped
    networks:
      - platform_net

  # =========================================================================
  # FIRECRAWL - Web Crawling for LLM-Friendly Document Ingestion
  # =========================================================================
  # NOTE: Firecrawl's Docker image is NOT publicly available on Docker Hub.
  # To use Firecrawl, you must build the image from source:
  #   git clone https://github.com/mendableai/firecrawl.git
  #   cd firecrawl && docker build -t firecrawl:local .
  # Then uncomment the service below and change image to: firecrawl:local
  #
  # firecrawl:
  #   image: firecrawl:local  # Built from https://github.com/mendableai/firecrawl
  #   container_name: ravenhelm-firecrawl
  #   labels:
  #     - "ravenhelm.project=hlidskjalf"
  #     - "ravenhelm.service=firecrawl"
  #     - "ravenhelm.workload=document-ingestion"
  #   ports:
  #     - "3002:3002"
  #   environment:
  #     - PORT=3002
  #     - NUM_WORKERS=2
  #     - OPENAI_API_KEY=${OPENAI_API_KEY}
  #     - REDIS_URL=redis://redis:6379
  #     - PLAYWRIGHT_MICROSERVICE_URL=http://playwright:3000
  #   volumes:
  #     - firecrawl_data:/data
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost:3002/health"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 3
  #     start_period: 60s
  #   restart: unless-stopped
  #   networks:
  #     - platform_net
  #   depends_on:
  #     - playwright
  #
  # # Playwright service for Firecrawl (headless browser)
  # playwright:
  #   image: browserless/chrome:latest
  #   container_name: ravenhelm-playwright
  #   labels:
  #     - "ravenhelm.project=hlidskjalf"
  #     - "ravenhelm.service=playwright"
  #     - "ravenhelm.workload=document-ingestion"
  #   environment:
  #     - MAX_CONCURRENT_SESSIONS=5
  #     - CONNECTION_TIMEOUT=60000
  #     - MAX_QUEUE_LENGTH=10
  #   ports:
  #     - "3030:3000"
  #   restart: unless-stopped
  #   networks:
  #     - platform_net

